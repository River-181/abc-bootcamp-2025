# 와이파이 연동 실시간 음성 출력 시스템 아키텍처

사용자의 앱에서 입력한 텍스트나 음성을 와이파이를 통해 아두이노(ESP32)에서 실시간으로 출력하는 시스템 구축 방안입니다.

### 전체 시스템 아키텍처

이 시스템의 핵심은 **실시간 양방향 통신**입니다. 이를 위해 중앙에 **웹소켓(WebSocket) 서버**를 두는 것이 가장 효율적입니다.

```
                               +-------------------------+
                               |   클라우드 TTS 서비스   |
                               | (Google, AWS 등)        |
                               +-----------+-------------+
                                           ^
                                           | (API 요청/응답)
+-------------+        +-------------------+-------------------+        +-----------------+
|  사용자 앱  |        |        백엔드 서버 (WebSocket)        |        |  아두이노(ESP32)  |
| (React, iOS)|<------>| - 사용자 인증, 기기 매칭              |<------>|   + I2S 앰프      |
|             |        | - TTS 처리, 오디오 데이터 중계(Broker) |        |   + 스피커        |
+-------------+        +---------------------------------------+        +-----------------+
```

### 핵심 구성 요소 및 역할

1.  **아두이노 (ESP32 사용 필수):**
    *   **하드웨어:** 그냥 아두이노가 아닌, **ESP32**를 사용해야 합니다. Wi-Fi 기능과 충분한 처리 능력을 갖추고 있기 때문입니다. 여기에 **I2S DAC/앰프 모듈(예: MAX98357A)**과 **스피커**를 연결합니다.
    *   **소프트웨어 역할:**
        1.  부팅 시 Wi-Fi에 접속합니다.
        2.  우리 백엔드 서버의 웹소켓 주소에 접속하여 연결을 유지합니다.
        3.  서버로부터 오디오 데이터(바이트 스트림)가 도착하면, 버퍼에 저장했다가 I2S 앰프를 통해 스피커로 즉시 출력합니다.

2.  **백엔드 서버 (Node.js, Python 등):**
    *   **역할:** 이 시스템의 '교통 관제사'입니다.
    *   **웹소켓 서버:** 앱과 ESP32 양쪽 모두의 연결을 받아들이고, 특정 앱과 특정 ESP32를 1:1로 매칭시켜 줍니다.
    *   **데이터 중계(Broker):** 앱에서 보낸 오디오 데이터를 해당 ESP32로 즉시 전달합니다.
    *   **TTS 처리:** 앱에서 텍스트를 받으면, 클라우드 TTS API에 요청을 보내 음성 파일(mp3/wav)을 받고, 이 데이터를 다시 ESP32로 스트리밍합니다.

3.  **사용자 앱 (모바일/웹):**
    *   **역할:** 사용자의 입력을 받아 서버로 전달하는 '리모컨'입니다.
    *   **UI:** 텍스트를 입력하는 창, 음성을 녹음하는 버튼 등을 제공합니다.
    *   **기능:**
        1.  서버의 웹소켓에 접속합니다.
        2.  텍스트를 입력하면, 해당 텍스트를 서버로 전송합니다.
        3.  음성을 녹음하면, 녹음된 오디오 데이터를 잘게 쪼개어(Chunk) 서버로 실시간 스트리밍합니다.

---

### 시나리오별 작동 방식

#### 시나리오 A: 사용자가 입력한 텍스트를 아두이노에서 출력하기

1.  **앱:** 사용자가 "안녕하세요"라고 입력하고 '전송' 버튼을 누릅니다. 앱은 이 텍스트를 웹소켓을 통해 서버로 보냅니다.
2.  **서버:** "안녕하세요" 텍스트를 수신합니다.
3.  **서버 -> 클라우드:** 서버는 Google Cloud TTS 같은 외부 API에 "이 텍스트를 한국어 여성 목소리 mp3 파일로 만들어줘"라고 요청합니다.
4.  **클라우드 -> 서버:** 클라우드 서비스가 생성한 mp3 오디오 데이터를 서버로 보내줍니다.
5.  **서버 -> ESP32:** 서버는 받은 mp3 데이터를 잘게 쪼개어, 웹소켓을 통해 해당 ESP32로 실시간 스트리밍합니다.
6.  **ESP32:** 오디오 데이터 조각들을 받는 즉시 스피커로 출력합니다. 사용자는 ESP32 스피커에서 "안녕하세요"라는 목소리를 듣게 됩니다.

#### 시나리오 B: 사용자가 녹음한 음성을 아두이노에서 출력하기

이것이 진정한 실시간 스트리밍입니다.

1.  **앱:** 사용자가 '녹음' 버튼을 누르고 말을 시작합니다. 앱은 마이크 입력을 받아, 오디오 데이터를 **0.1초** 같은 매우 짧은 단위로 계속해서 서버에 웹소켓으로 전송합니다.
2.  **서버:** 앱으로부터 받은 오디오 데이터 조각을 받는 즉시, 매칭된 ESP32의 웹소켓으로 **그대로 전달(Relay)**합니다. 서버는 데이터의 내용을 분석할 필요 없이 중계만 합니다.
3.  **ESP32:** 서버로부터 전달받은 오디오 데이터 조각들을 순서대로 스피커에 출력합니다.
4.  **결과:** 거의 지연시간 없이, 사용자가 앱에 대고 말하는 목소리가 ESP32 스피커에서 그대로 흘러나옵니다. (마치 워키토키처럼)

---

### 결론

이 시스템의 성공적인 구현을 위해서는
*   **하드웨어:** **ESP32 + I2S 앰프/DAC + 스피커** 조합이 필수적이며,
*   **소프트웨어:** **웹소켓(WebSocket)**을 이용한 실시간 양방향 통신 아키텍처를 구축하는 것이 핵심입니다.
